#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‚½æ®µåˆ†ç»„åˆ†ææ¨¡å—

æ ¹æ®ä¿®é¥°æ£€æµ‹æƒ…å†µå°†è‚½æ®µåˆ†ä¸ºä¸‰ç»„è¿›è¡Œæ¯”è¾ƒåˆ†æï¼š
- PTM-only: åªæ£€æµ‹åˆ°ä¿®é¥°å½¢æ€
- PTM + WT: åŒåºåˆ—åŒæ—¶æ£€æµ‹åˆ°ä¿®é¥°ä¸æœªä¿®é¥°è‚½
- WT-only: åªæ£€æµ‹åˆ°æœªä¿®é¥°è‚½

ä½œè€…: Tumor Proteomics Analysis Team
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import kruskal
import warnings
warnings.filterwarnings('ignore')

# å°è¯•å¯¼å…¥ç»Ÿè®¡æ£€éªŒåŒ…
try:
    from scipy.stats import dunn
    DUNN_AVAILABLE = True
except ImportError:
    try:
        import scikit_posthocs as sp
        DUNN_AVAILABLE = True
        USE_SCIKIT_POSTHOCS = True
    except ImportError:
        DUNN_AVAILABLE = False
        USE_SCIKIT_POSTHOCS = False

# å°è¯•å¯¼å…¥è¿›åº¦æ¡
try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False

# å¯¼å…¥æ ¸å¿ƒåˆ†æå™¨
from tumor_analysis_core import TumorAnalysisCore

class PeptideGroupAnalyzer:
    """è‚½æ®µåˆ†ç»„åˆ†æå™¨"""
    
    def __init__(self, enable_resume=True):
        self.core_analyzer = TumorAnalysisCore()

        # ç›®æ ‡ä¿®é¥°ç±»å‹ï¼ˆæ’é™¤æ°§åŒ–ä¿®é¥°ï¼‰
        self.target_modifications = [
            'Phospho[S]', 'Phospho[T]', 'Phospho[Y]',
            'Acetyl[K]', 'Methyl[K]', 'Dimethyl[K]', 'Trimethyl[K]',
            'Deamidated[N]', 'Deamidated[Q]'
        ]

        # ç†åŒ–æ€§è´¨åˆ—å
        self.property_columns = [
            'corrected_pi', 'corrected_charge_at_ph7',
            'corrected_hydrophobicity_kd', 'corrected_molecular_weight'
        ]

        self.property_names = ['pI', 'Net_Charge', 'Hydrophobicity_KD', 'Molecular_Weight']

        # è¾“å‡ºç›®å½•
        self.output_dir = 'peptide_group_analysis_results'
        self.fig_dir = os.path.join(self.output_dir, 'fig')
        self.cache_dir = os.path.join(self.output_dir, 'cache')

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(self.fig_dir, exist_ok=True)
        os.makedirs(self.cache_dir, exist_ok=True)

        # æ–­ç‚¹ç»­ä¼ è®¾ç½®
        self.enable_resume = enable_resume
        self.progress_file = os.path.join(self.cache_dir, 'analysis_progress.json')
        self.completed_datasets = self.load_progress() if enable_resume else set()

    def load_progress(self) -> set:
        """åŠ è½½åˆ†æè¿›åº¦"""
        try:
            if os.path.exists(self.progress_file):
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    import json
                    progress_data = json.load(f)
                    completed = set(progress_data.get('completed_datasets', []))
                    print(f"ğŸ“‹ åŠ è½½æ–­ç‚¹ç»­ä¼ è¿›åº¦: å·²å®Œæˆ {len(completed)} ä¸ªæ•°æ®é›†")
                    if completed:
                        print(f"  å·²å®Œæˆæ•°æ®é›†: {', '.join(sorted(completed))}")
                    return completed
        except Exception as e:
            print(f"âš ï¸  åŠ è½½è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")
        return set()

    def save_progress(self, completed_dataset: str = None):
        """ä¿å­˜åˆ†æè¿›åº¦"""
        try:
            if completed_dataset:
                self.completed_datasets.add(completed_dataset)

            import json
            progress_data = {
                'completed_datasets': list(self.completed_datasets),
                'last_updated': pd.Timestamp.now().isoformat(),
                'total_completed': len(self.completed_datasets)
            }

            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(progress_data, f, indent=2, ensure_ascii=False)

            if completed_dataset:
                print(f"ğŸ’¾ ä¿å­˜è¿›åº¦: {completed_dataset} å·²å®Œæˆ ({len(self.completed_datasets)} ä¸ªæ•°æ®é›†)")

        except Exception as e:
            print(f"âš ï¸  ä¿å­˜è¿›åº¦å¤±è´¥: {e}")

    def is_dataset_completed(self, dataset_id: str) -> bool:
        """æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å·²å®Œæˆåˆ†æ"""
        return self.enable_resume and dataset_id in self.completed_datasets

    def load_cached_results(self, dataset_id: str) -> tuple:
        """åŠ è½½ç¼“å­˜çš„åˆ†æç»“æœ"""
        try:
            cache_file = os.path.join(self.cache_dir, f'{dataset_id}_results.pkl')
            if os.path.exists(cache_file):
                import pickle
                with open(cache_file, 'rb') as f:
                    cached_results = pickle.load(f)
                    print(f"ğŸ“‚ åŠ è½½ç¼“å­˜ç»“æœ: {dataset_id}")
                    return cached_results.get('group_stats'), cached_results.get('stat_tests')
        except Exception as e:
            print(f"âš ï¸  åŠ è½½ç¼“å­˜å¤±è´¥ {dataset_id}: {e}")
        return None, None

    def save_cached_results(self, dataset_id: str, group_stats: pd.DataFrame, stat_tests: pd.DataFrame):
        """ä¿å­˜åˆ†æç»“æœåˆ°ç¼“å­˜"""
        try:
            cache_file = os.path.join(self.cache_dir, f'{dataset_id}_results.pkl')
            import pickle
            cached_results = {
                'group_stats': group_stats,
                'stat_tests': stat_tests,
                'timestamp': pd.Timestamp.now().isoformat()
            }
            with open(cache_file, 'wb') as f:
                pickle.dump(cached_results, f)
            print(f"ğŸ’¾ ç¼“å­˜ç»“æœ: {dataset_id}")
        except Exception as e:
            print(f"âš ï¸  ç¼“å­˜ä¿å­˜å¤±è´¥ {dataset_id}: {e}")

    def clear_cache(self):
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜"""
        try:
            import shutil
            if os.path.exists(self.cache_dir):
                shutil.rmtree(self.cache_dir)
                os.makedirs(self.cache_dir, exist_ok=True)
                self.completed_datasets = set()
                print("ğŸ—‘ï¸  å·²æ¸…é™¤æ‰€æœ‰ç¼“å­˜")
        except Exception as e:
            print(f"âš ï¸  æ¸…é™¤ç¼“å­˜å¤±è´¥: {e}")

    def classify_peptides_by_detection_per_modification(self, dataset_data: pd.DataFrame,
                                                       modification_type: str) -> pd.DataFrame:
        """
        é’ˆå¯¹ç‰¹å®šä¿®é¥°ç±»å‹ï¼Œæ ¹æ®æ£€æµ‹æƒ…å†µå¯¹è‚½æ®µè¿›è¡Œåˆ†ç»„

        Args:
            dataset_data: æ•°æ®é›†æ•°æ®
            modification_type: ç‰¹å®šä¿®é¥°ç±»å‹ï¼Œå¦‚'Acetyl[K]'

        Returns:
            DataFrame with additional 'peptide_group' column
        """
        print(f"ğŸ” åˆ†æ {modification_type} çš„è‚½æ®µæ£€æµ‹æƒ…å†µ...")

        # åªä¿ç•™è¯¥ç‰¹å®šä¿®é¥°å’Œæ— ä¿®é¥°è‚½æ®µ
        target_data = dataset_data[
            (dataset_data['modification_type'] == modification_type) |
            (dataset_data['num_modifications'] == 0)
        ].copy()

        if len(target_data) == 0:
            print(f"âš ï¸  æ²¡æœ‰æ‰¾åˆ° {modification_type} ä¿®é¥°æ•°æ®")
            return pd.DataFrame()

        # ç»Ÿè®¡æ¯ä¸ªåºåˆ—çš„æ£€æµ‹æƒ…å†µ
        sequence_stats = target_data.groupby('sequence').agg({
            'num_modifications': ['min', 'max', 'count'],
            'modification_type': lambda x: list(x.unique())
        }).reset_index()

        # æ‰å¹³åŒ–åˆ—å
        sequence_stats.columns = ['sequence', 'min_mods', 'max_mods', 'total_count', 'mod_types']

        # åˆ†ç±»é€»è¾‘ï¼ˆé’ˆå¯¹ç‰¹å®šä¿®é¥°ï¼‰
        def classify_sequence_for_modification(row):
            min_mods = row['min_mods']
            max_mods = row['max_mods']
            mod_types = row['mod_types']

            # ç§»é™¤NaNå€¼
            mod_types = [x for x in mod_types if pd.notna(x) and x != '']

            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡ä¿®é¥°
            has_target_mod = modification_type in mod_types
            has_unmodified = None in mod_types or '' in mod_types or min_mods == 0

            if has_target_mod and has_unmodified:
                return 'PTM + WT'  # åŒæ—¶æ£€æµ‹åˆ°ä¿®é¥°å’Œæœªä¿®é¥°
            elif has_target_mod and not has_unmodified:
                return 'PTM-only'  # åªæ£€æµ‹åˆ°ä¿®é¥°
            elif not has_target_mod and has_unmodified:
                return 'WT-only'   # åªæ£€æµ‹åˆ°æœªä¿®é¥°
            else:
                return 'Unknown'

        sequence_stats['peptide_group'] = sequence_stats.apply(classify_sequence_for_modification, axis=1)

        # åˆå¹¶å›åŸæ•°æ®
        target_data = target_data.merge(
            sequence_stats[['sequence', 'peptide_group']],
            on='sequence',
            how='left'
        )

        # ç»Ÿè®¡å„ç»„æ•°é‡
        group_counts = target_data['peptide_group'].value_counts()
        print(f"ğŸ“Š {modification_type} è‚½æ®µåˆ†ç»„ç»Ÿè®¡:")
        for group, count in group_counts.items():
            print(f"  {group}: {count:,} æ¡è®°å½•")

        return target_data

    def calculate_group_statistics_per_modification(self, grouped_data: pd.DataFrame,
                                                   dataset_id: str, modification_type: str) -> pd.DataFrame:
        """è®¡ç®—ç‰¹å®šä¿®é¥°ç±»å‹å„ç»„çš„ç»Ÿè®¡é‡"""

        stats_list = []

        for group in ['PTM-only', 'PTM + WT', 'WT-only']:
            group_data = grouped_data[grouped_data['peptide_group'] == group]

            if len(group_data) == 0:
                continue

            for i, prop_col in enumerate(self.property_columns):
                prop_name = self.property_names[i]
                values = group_data[prop_col].dropna()

                if len(values) > 0:
                    stats_list.append({
                        'dataset_id': dataset_id,
                        'modification_type': modification_type,
                        'peptide_group': group,
                        'property': prop_name,
                        'count': len(values),
                        'median': values.median(),
                        'mean': values.mean(),
                        'std': values.std(),
                        'q25': values.quantile(0.25),
                        'q75': values.quantile(0.75),
                        'min': values.min(),
                        'max': values.max()
                    })

        return pd.DataFrame(stats_list)

    def calculate_group_statistics(self, grouped_data: pd.DataFrame, dataset_id: str) -> pd.DataFrame:
        """è®¡ç®—å„ç»„çš„ç»Ÿè®¡é‡"""
        
        stats_list = []
        
        for group in ['PTM-only', 'PTM + WT', 'WT-only']:
            group_data = grouped_data[grouped_data['peptide_group'] == group]
            
            if len(group_data) == 0:
                continue
            
            for i, prop_col in enumerate(self.property_columns):
                prop_name = self.property_names[i]
                values = group_data[prop_col].dropna()
                
                if len(values) > 0:
                    stats_list.append({
                        'dataset_id': dataset_id,
                        'peptide_group': group,
                        'property': prop_name,
                        'count': len(values),
                        'median': values.median(),
                        'mean': values.mean(),
                        'std': values.std(),
                        'q25': values.quantile(0.25),
                        'q75': values.quantile(0.75),
                        'min': values.min(),
                        'max': values.max()
                    })
        
        return pd.DataFrame(stats_list)

    def perform_statistical_tests_per_modification(self, grouped_data: pd.DataFrame,
                                                  dataset_id: str, modification_type: str) -> pd.DataFrame:
        """æ‰§è¡Œç‰¹å®šä¿®é¥°ç±»å‹çš„ç»Ÿè®¡æ£€éªŒ"""

        test_results = []

        for i, prop_col in enumerate(self.property_columns):
            prop_name = self.property_names[i]

            # å‡†å¤‡ä¸‰ç»„æ•°æ®
            groups = {}
            for group_name in ['PTM-only', 'PTM + WT', 'WT-only']:
                group_data = grouped_data[grouped_data['peptide_group'] == group_name]
                values = group_data[prop_col].dropna()
                if len(values) >= 3:  # è‡³å°‘éœ€è¦3ä¸ªå€¼
                    groups[group_name] = values

            if len(groups) < 2:
                continue

            # Kruskal-Wallisæ£€éªŒ
            group_values = list(groups.values())
            if len(group_values) >= 2:
                try:
                    h_stat, p_value = kruskal(*group_values)

                    test_results.append({
                        'dataset_id': dataset_id,
                        'modification_type': modification_type,
                        'property': prop_name,
                        'test_type': 'Kruskal-Wallis',
                        'comparison': 'Overall',
                        'statistic': h_stat,
                        'p_value': p_value,
                        'significant': p_value < 0.05,
                        'effect_size': np.nan,
                        'group1': 'All',
                        'group2': 'All'
                    })

                    # å¦‚æœæ€»ä½“æ£€éªŒæ˜¾è‘—ï¼Œè¿›è¡Œäº‹åæ£€éªŒ
                    if p_value < 0.05 and len(groups) >= 2:
                        group_names = list(groups.keys())

                        # ä¸¤ä¸¤æ¯”è¾ƒ
                        for j in range(len(group_names)):
                            for k in range(j+1, len(group_names)):
                                group1_name = group_names[j]
                                group2_name = group_names[k]
                                group1_values = groups[group1_name]
                                group2_values = groups[group2_name]

                                # Mann-Whitney Uæ£€éªŒ
                                try:
                                    u_stat, u_p = stats.mannwhitneyu(
                                        group1_values, group2_values,
                                        alternative='two-sided'
                                    )

                                    # è®¡ç®—æ•ˆåº”é‡ (Cliff's delta approximation)
                                    n1, n2 = len(group1_values), len(group2_values)
                                    effect_size = (u_stat / (n1 * n2)) * 2 - 1

                                    test_results.append({
                                        'dataset_id': dataset_id,
                                        'modification_type': modification_type,
                                        'property': prop_name,
                                        'test_type': 'Mann-Whitney U',
                                        'comparison': f'{group1_name} vs {group2_name}',
                                        'statistic': u_stat,
                                        'p_value': u_p,
                                        'significant': u_p < 0.05,
                                        'effect_size': effect_size,
                                        'group1': group1_name,
                                        'group2': group2_name
                                    })
                                except Exception as e:
                                    print(f"âš ï¸  ä¸¤ä¸¤æ¯”è¾ƒå¤±è´¥ {group1_name} vs {group2_name}: {e}")
                                    continue

                except Exception as e:
                    print(f"âš ï¸  Kruskal-Wallisæ£€éªŒå¤±è´¥ {prop_name}: {e}")
                    continue

        return pd.DataFrame(test_results)

    def perform_statistical_tests(self, grouped_data: pd.DataFrame, dataset_id: str) -> pd.DataFrame:
        """æ‰§è¡Œç»Ÿè®¡æ£€éªŒ"""
        
        test_results = []
        
        for i, prop_col in enumerate(self.property_columns):
            prop_name = self.property_names[i]
            
            # å‡†å¤‡ä¸‰ç»„æ•°æ®
            groups = {}
            for group_name in ['PTM-only', 'PTM + WT', 'WT-only']:
                group_data = grouped_data[grouped_data['peptide_group'] == group_name]
                values = group_data[prop_col].dropna()
                if len(values) >= 3:  # è‡³å°‘éœ€è¦3ä¸ªå€¼
                    groups[group_name] = values
            
            if len(groups) < 2:
                continue
            
            # Kruskal-Wallisæ£€éªŒ
            group_values = list(groups.values())
            if len(group_values) >= 2:
                try:
                    h_stat, p_value = kruskal(*group_values)
                    
                    test_results.append({
                        'dataset_id': dataset_id,
                        'property': prop_name,
                        'test_type': 'Kruskal-Wallis',
                        'comparison': 'Overall',
                        'statistic': h_stat,
                        'p_value': p_value,
                        'significant': p_value < 0.05,
                        'effect_size': np.nan,
                        'group1': 'All',
                        'group2': 'All'
                    })
                    
                    # å¦‚æœæ€»ä½“æ£€éªŒæ˜¾è‘—ï¼Œè¿›è¡Œäº‹åæ£€éªŒ
                    if p_value < 0.05 and len(groups) >= 2:
                        group_names = list(groups.keys())
                        
                        # ä¸¤ä¸¤æ¯”è¾ƒ
                        for j in range(len(group_names)):
                            for k in range(j+1, len(group_names)):
                                group1_name = group_names[j]
                                group2_name = group_names[k]
                                group1_values = groups[group1_name]
                                group2_values = groups[group2_name]
                                
                                # Mann-Whitney Uæ£€éªŒ
                                try:
                                    u_stat, u_p = stats.mannwhitneyu(
                                        group1_values, group2_values, 
                                        alternative='two-sided'
                                    )
                                    
                                    # è®¡ç®—æ•ˆåº”é‡ (Cliff's delta approximation)
                                    n1, n2 = len(group1_values), len(group2_values)
                                    effect_size = (u_stat / (n1 * n2)) * 2 - 1
                                    
                                    test_results.append({
                                        'dataset_id': dataset_id,
                                        'property': prop_name,
                                        'test_type': 'Mann-Whitney U',
                                        'comparison': f'{group1_name} vs {group2_name}',
                                        'statistic': u_stat,
                                        'p_value': u_p,
                                        'significant': u_p < 0.05,
                                        'effect_size': effect_size,
                                        'group1': group1_name,
                                        'group2': group2_name
                                    })
                                except Exception as e:
                                    print(f"âš ï¸  ä¸¤ä¸¤æ¯”è¾ƒå¤±è´¥ {group1_name} vs {group2_name}: {e}")
                                    continue
                
                except Exception as e:
                    print(f"âš ï¸  Kruskal-Wallisæ£€éªŒå¤±è´¥ {prop_name}: {e}")
                    continue
        
        return pd.DataFrame(test_results)
    
    def create_box_violin_plots(self, grouped_data: pd.DataFrame, dataset_id: str):
        """åˆ›å»ºåˆå¹¶çš„ç®±çº¿å›¾/å°æç´å›¾ï¼ˆ4ä¸ªç†åŒ–æ€§è´¨åœ¨ä¸€å¼ å›¾ä¸Šï¼‰"""

        print(f"ğŸ“Š ç»˜åˆ¶ {dataset_id} çš„åˆå¹¶å¯è§†åŒ–å›¾è¡¨...")

        # è®¾ç½®å›¾å½¢æ ·å¼
        plt.style.use('default')
        sns.set_palette("Set2")

        # åˆ›å»º2x2å­å›¾å¸ƒå±€
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle(f'{dataset_id} - All Modifications - Physicochemical Properties by Peptide Group',
                    fontsize=16, fontweight='bold')

        axes = axes.flatten()

        # ä¸ºæ¯ä¸ªç†åŒ–æ€§è´¨åˆ›å»ºå­å›¾
        for i, prop_col in enumerate(self.property_columns):
            prop_name = self.property_names[i]
            ax = axes[i]

            # å‡†å¤‡æ•°æ®
            plot_data = []
            for group in ['PTM-only', 'PTM + WT', 'WT-only']:
                group_data = grouped_data[grouped_data['peptide_group'] == group]
                values = group_data[prop_col].dropna()

                if len(values) > 0:
                    for value in values:
                        plot_data.append({
                            'Group': group,
                            'Value': value,
                            'Property': prop_name
                        })

            if len(plot_data) == 0:
                ax.text(0.5, 0.5, f'No data for {prop_name}',
                       ha='center', va='center', transform=ax.transAxes)
                ax.set_title(f'{prop_name}')
                continue

            plot_df = pd.DataFrame(plot_data)

            # å‡†å¤‡åˆ†ç»„æ•°æ®ç”¨äºç»Ÿè®¡æ£€éªŒ
            groups_data = {}
            for group in ['PTM-only', 'PTM + WT', 'WT-only']:
                group_data = grouped_data[grouped_data['peptide_group'] == group]
                values = group_data[prop_col].dropna()
                if len(values) > 0:
                    groups_data[group] = values

            # ç»˜åˆ¶æ›´çª„çš„å°æç´å›¾ + ç®±çº¿å›¾
            sns.violinplot(data=plot_df, x='Group', y='Value', ax=ax,
                          alpha=0.6, width=0.6, inner=None)  # æ›´çª„çš„å°æç´å›¾
            sns.boxplot(data=plot_df, x='Group', y='Value', ax=ax,
                       width=0.2, boxprops=dict(alpha=0.9),
                       whiskerprops=dict(linewidth=1.5),
                       capprops=dict(linewidth=1.5))  # æ›´çª„çš„ç®±çº¿å›¾

            # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
            ax.set_title(f'{prop_name}', fontsize=14, fontweight='bold')
            ax.set_xlabel('Peptide Group', fontsize=12)
            ax.set_ylabel(f'{prop_name}', fontsize=12)

            # æ‰§è¡Œç»Ÿè®¡æ£€éªŒå¹¶æ·»åŠ æ˜¾è‘—æ€§æ ‡æ³¨
            self.add_significance_annotations(ax, groups_data, plot_df)

            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            group_stats = plot_df.groupby('Group')['Value'].agg(['count', 'median']).round(3)
            stats_text = '\n'.join([f'{group}: n={row["count"]}, median={row["median"]}'
                                   for group, row in group_stats.iterrows()])
            ax.text(0.02, 0.02, stats_text, transform=ax.transAxes,
                   verticalalignment='bottom', fontsize=9,
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

            # æ—‹è½¬xè½´æ ‡ç­¾
            ax.tick_params(axis='x', rotation=45)
            ax.grid(True, alpha=0.3)

        plt.tight_layout()

        # ä¿å­˜å›¾ç‰‡
        filename = f'combined_properties_{dataset_id}_all_modifications.png'
        filepath = os.path.join(self.fig_dir, filename)
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"  âœ… ä¿å­˜: {filename}")

    def create_box_violin_plots_per_modification(self, grouped_data: pd.DataFrame,
                                                dataset_id: str, modification_type: str):
        """ä¸ºç‰¹å®šä¿®é¥°ç±»å‹åˆ›å»ºåˆå¹¶çš„ç®±çº¿å›¾/å°æç´å›¾ï¼ˆ4ä¸ªç†åŒ–æ€§è´¨åœ¨ä¸€å¼ å›¾ä¸Šï¼‰"""

        print(f"ğŸ“Š ç»˜åˆ¶ {dataset_id} - {modification_type} çš„åˆå¹¶å¯è§†åŒ–å›¾è¡¨...")

        # è®¾ç½®å›¾å½¢æ ·å¼
        plt.style.use('default')
        sns.set_palette("Set2")

        # åˆ›å»º2x2å­å›¾å¸ƒå±€
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle(f'{dataset_id} - {modification_type} - Physicochemical Properties by Peptide Group',
                    fontsize=16, fontweight='bold')

        axes = axes.flatten()

        # ä¸ºæ¯ä¸ªç†åŒ–æ€§è´¨åˆ›å»ºå­å›¾
        for i, prop_col in enumerate(self.property_columns):
            prop_name = self.property_names[i]
            ax = axes[i]

            # å‡†å¤‡æ•°æ®
            plot_data = []
            groups_data = {}
            for group in ['PTM-only', 'PTM + WT', 'WT-only']:
                group_data = grouped_data[grouped_data['peptide_group'] == group]
                values = group_data[prop_col].dropna()

                if len(values) > 0:
                    groups_data[group] = values
                    for value in values:
                        plot_data.append({
                            'Group': group,
                            'Value': value,
                            'Property': prop_name
                        })

            if len(plot_data) == 0:
                ax.text(0.5, 0.5, f'No data for {prop_name}',
                       ha='center', va='center', transform=ax.transAxes)
                ax.set_title(f'{prop_name}')
                continue

            plot_df = pd.DataFrame(plot_data)

            # ç»˜åˆ¶æ›´çª„çš„å°æç´å›¾ + ç®±çº¿å›¾
            sns.violinplot(data=plot_df, x='Group', y='Value', ax=ax,
                          alpha=0.6, width=0.6, inner=None)  # æ›´çª„çš„å°æç´å›¾
            sns.boxplot(data=plot_df, x='Group', y='Value', ax=ax,
                       width=0.2, boxprops=dict(alpha=0.9),
                       whiskerprops=dict(linewidth=1.5),
                       capprops=dict(linewidth=1.5))  # æ›´çª„çš„ç®±çº¿å›¾

            # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
            ax.set_title(f'{prop_name}', fontsize=14, fontweight='bold')
            ax.set_xlabel('Peptide Group', fontsize=12)
            ax.set_ylabel(f'{prop_name}', fontsize=12)

            # æ‰§è¡Œç»Ÿè®¡æ£€éªŒå¹¶æ·»åŠ æ˜¾è‘—æ€§æ ‡æ³¨
            self.add_significance_annotations(ax, groups_data, plot_df)

            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            group_stats = plot_df.groupby('Group')['Value'].agg(['count', 'median']).round(3)
            stats_text = '\n'.join([f'{group}: n={row["count"]}, median={row["median"]}'
                                   for group, row in group_stats.iterrows()])
            ax.text(0.02, 0.02, stats_text, transform=ax.transAxes,
                   verticalalignment='bottom', fontsize=9,
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

            # æ—‹è½¬xè½´æ ‡ç­¾
            ax.tick_params(axis='x', rotation=45)
            ax.grid(True, alpha=0.3)

        plt.tight_layout()

        # ä¿å­˜å›¾ç‰‡
        # æ¸…ç†ä¿®é¥°ç±»å‹åç§°ç”¨äºæ–‡ä»¶å
        clean_mod_name = modification_type.replace('[', '_').replace(']', '_').replace('/', '_')
        filename = f'combined_properties_{dataset_id}_{clean_mod_name}.png'
        filepath = os.path.join(self.fig_dir, filename)
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"  âœ… ä¿å­˜: {filename}")

    def add_significance_annotations(self, ax, groups_data: dict, plot_df: pd.DataFrame):
        """æ·»åŠ æ˜¾è‘—æ€§æ£€éªŒçš„på€¼æ ‡æ³¨"""

        try:
            from scipy import stats

            # è·å–ç»„åå’Œå¯¹åº”çš„xè½´ä½ç½®
            group_names = ['PTM-only', 'PTM + WT', 'WT-only']
            available_groups = [g for g in group_names if g in groups_data and len(groups_data[g]) >= 3]

            if len(available_groups) < 2:
                return

            # æ‰§è¡ŒKruskal-Wallisæ£€éªŒ
            group_values = [groups_data[g] for g in available_groups]
            try:
                h_stat, kw_p = stats.kruskal(*group_values)

                # åœ¨å›¾è¡¨é¡¶éƒ¨æ·»åŠ æ€»ä½“æ£€éªŒç»“æœ
                y_max = plot_df['Value'].max()
                y_range = plot_df['Value'].max() - plot_df['Value'].min()

                # Kruskal-Wallisç»“æœ
                kw_text = f'Kruskal-Wallis: p={kw_p:.2e}' if kw_p < 0.001 else f'Kruskal-Wallis: p={kw_p:.3f}'
                if kw_p < 0.001:
                    kw_text += ' ***'
                elif kw_p < 0.01:
                    kw_text += ' **'
                elif kw_p < 0.05:
                    kw_text += ' *'
                else:
                    kw_text += ' ns'

                ax.text(0.5, 0.98, kw_text, transform=ax.transAxes,
                       ha='center', va='top', fontsize=10, fontweight='bold',
                       bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.8))

                # å¦‚æœæ€»ä½“æ£€éªŒæ˜¾è‘—ï¼Œè¿›è¡Œä¸¤ä¸¤æ¯”è¾ƒ
                if kw_p < 0.05 and len(available_groups) >= 2:
                    y_offset = y_max + y_range * 0.05

                    # ä¸¤ä¸¤æ¯”è¾ƒ
                    comparisons = []
                    for j in range(len(available_groups)):
                        for k in range(j+1, len(available_groups)):
                            group1 = available_groups[j]
                            group2 = available_groups[k]

                            try:
                                u_stat, u_p = stats.mannwhitneyu(
                                    groups_data[group1], groups_data[group2],
                                    alternative='two-sided'
                                )

                                # è·å–xè½´ä½ç½®
                                x1 = group_names.index(group1)
                                x2 = group_names.index(group2)

                                comparisons.append({
                                    'x1': x1, 'x2': x2, 'p': u_p,
                                    'group1': group1, 'group2': group2
                                })

                            except Exception as e:
                                continue

                    # ç»˜åˆ¶æ˜¾è‘—æ€§æ ‡æ³¨
                    for idx, comp in enumerate(comparisons):
                        if comp['p'] < 0.05:  # åªæ ‡æ³¨æ˜¾è‘—çš„æ¯”è¾ƒ
                            x1, x2 = comp['x1'], comp['x2']
                            p_val = comp['p']

                            # ç¡®å®šæ˜¾è‘—æ€§ç¬¦å·
                            if p_val < 0.001:
                                sig_symbol = '***'
                            elif p_val < 0.01:
                                sig_symbol = '**'
                            elif p_val < 0.05:
                                sig_symbol = '*'
                            else:
                                continue

                            # è®¡ç®—æ ‡æ³¨ä½ç½®
                            y_pos = y_offset + idx * y_range * 0.08

                            # ç»˜åˆ¶è¿æ¥çº¿
                            ax.plot([x1, x2], [y_pos, y_pos], 'k-', linewidth=1)
                            ax.plot([x1, x1], [y_pos - y_range*0.01, y_pos], 'k-', linewidth=1)
                            ax.plot([x2, x2], [y_pos - y_range*0.01, y_pos], 'k-', linewidth=1)

                            # æ·»åŠ på€¼å’Œæ˜¾è‘—æ€§ç¬¦å·
                            p_text = f'{sig_symbol}\np={p_val:.2e}' if p_val < 0.001 else f'{sig_symbol}\np={p_val:.3f}'
                            ax.text((x1 + x2) / 2, y_pos + y_range*0.02, p_text,
                                   ha='center', va='bottom', fontsize=8, fontweight='bold')

            except Exception as e:
                print(f"âš ï¸  ç»Ÿè®¡æ£€éªŒå¤±è´¥: {e}")

        except ImportError:
            print("âš ï¸  scipyæœªå®‰è£…ï¼Œè·³è¿‡æ˜¾è‘—æ€§æ ‡æ³¨")
        except Exception as e:
            print(f"âš ï¸  æ·»åŠ æ˜¾è‘—æ€§æ ‡æ³¨å¤±è´¥: {e}")

    def analyze_single_dataset(self, dataset_id: str) -> tuple:
        """åˆ†æå•ä¸ªæ•°æ®é›† - å¯¹æ¯ç§ä¿®é¥°ç±»å‹åˆ†åˆ«è¿›è¡Œä¸‰ç»„æ¯”è¾ƒ"""

        print(f"\nğŸ”¬ åˆ†ææ•°æ®é›†: {dataset_id}")

        # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆåˆ†æ
        if self.is_dataset_completed(dataset_id):
            print(f"âœ… æ•°æ®é›† {dataset_id} å·²å®Œæˆåˆ†æï¼Œä»ç¼“å­˜åŠ è½½ç»“æœ")
            cached_group_stats, cached_stat_tests = self.load_cached_results(dataset_id)
            if cached_group_stats is not None and cached_stat_tests is not None:
                return None, cached_group_stats, cached_stat_tests
            else:
                print(f"âš ï¸  ç¼“å­˜æ–‡ä»¶æŸåï¼Œé‡æ–°åˆ†æ {dataset_id}")
                # ä»å·²å®Œæˆåˆ—è¡¨ä¸­ç§»é™¤ï¼Œé‡æ–°åˆ†æ
                self.completed_datasets.discard(dataset_id)

        try:
            # è·å–è‚¿ç˜¤æ ·æœ¬æ•°æ®
            tumor_files = self.core_analyzer.get_tumor_samples(dataset_id)

            if len(tumor_files) == 0:
                print(f"âš ï¸  æ•°æ®é›† {dataset_id}: æ— è‚¿ç˜¤æ ·æœ¬")
                return None, None, None

            print(f"ğŸ“ æ‰¾åˆ° {len(tumor_files)} ä¸ªè‚¿ç˜¤æ ·æœ¬æ–‡ä»¶")

            # æ”¶é›†æ‰€æœ‰æ–‡ä»¶çš„æ•°æ®
            all_data = []

            for file_name in tumor_files:
                spectra_file = self.core_analyzer.find_spectra_file(dataset_id, file_name)

                if spectra_file is None:
                    continue

                file_data = self.core_analyzer.analyze_single_file(spectra_file, dataset_id)
                if file_data is not None and len(file_data) > 0:
                    all_data.append(file_data)

            if len(all_data) == 0:
                print(f"âŒ æ•°æ®é›† {dataset_id}: æ— æœ‰æ•ˆæ•°æ®")
                return None, None, None

            # åˆå¹¶æ•°æ®
            dataset_data = pd.concat(all_data, ignore_index=True)
            print(f"âœ… åˆå¹¶å¾—åˆ° {len(dataset_data)} æ¡è®°å½•")

            # å¯¹æ¯ç§ä¿®é¥°ç±»å‹åˆ†åˆ«è¿›è¡Œåˆ†æ
            all_group_stats = []
            all_stat_tests = []

            for modification_type in self.target_modifications:
                print(f"\nğŸ¯ åˆ†æä¿®é¥°ç±»å‹: {modification_type}")

                # é’ˆå¯¹è¯¥ä¿®é¥°ç±»å‹è¿›è¡Œè‚½æ®µåˆ†ç»„
                grouped_data = self.classify_peptides_by_detection_per_modification(
                    dataset_data, modification_type)

                if len(grouped_data) == 0:
                    print(f"âš ï¸  {modification_type}: æ— æœ‰æ•ˆåˆ†ç»„æ•°æ®")
                    continue

                # è®¡ç®—ç»Ÿè®¡é‡
                group_stats = self.calculate_group_statistics_per_modification(
                    grouped_data, dataset_id, modification_type)

                if len(group_stats) > 0:
                    all_group_stats.append(group_stats)

                # ç»Ÿè®¡æ£€éªŒ
                stat_tests = self.perform_statistical_tests_per_modification(
                    grouped_data, dataset_id, modification_type)

                if len(stat_tests) > 0:
                    all_stat_tests.append(stat_tests)

                # åˆ›å»ºå¯è§†åŒ–
                self.create_box_violin_plots_per_modification(
                    grouped_data, dataset_id, modification_type)

            # åˆå¹¶æ‰€æœ‰ä¿®é¥°ç±»å‹çš„ç»“æœ
            if len(all_group_stats) > 0:
                final_group_stats = pd.concat(all_group_stats, ignore_index=True)
            else:
                final_group_stats = pd.DataFrame()

            if len(all_stat_tests) > 0:
                final_stat_tests = pd.concat(all_stat_tests, ignore_index=True)
            else:
                final_stat_tests = pd.DataFrame()

            # ä¿å­˜ç»“æœåˆ°ç¼“å­˜å¹¶æ ‡è®°ä¸ºå·²å®Œæˆ
            if len(final_group_stats) > 0:
                self.save_cached_results(dataset_id, final_group_stats, final_stat_tests)
                self.save_progress(dataset_id)
                print(f"âœ… æ•°æ®é›† {dataset_id} åˆ†æå®Œæˆå¹¶å·²ç¼“å­˜")

            return dataset_data, final_group_stats, final_stat_tests

        except Exception as e:
            print(f"âŒ åˆ†ææ•°æ®é›† {dataset_id} æ—¶å‡ºé”™: {e}")
            return None, None, None

    def run_full_analysis(self, max_datasets: int = None):
        """è¿è¡Œå®Œæ•´çš„åˆ†ç»„åˆ†æ"""

        print("ğŸ§¬ å¼€å§‹è‚½æ®µåˆ†ç»„åˆ†æ...")
        print("=" * 60)

        # è·å–ç™Œç—‡æ•°æ®é›†
        cancer_datasets = self.core_analyzer.load_cancer_datasets()

        if len(cancer_datasets) == 0:
            print("âŒ æœªæ‰¾åˆ°ç™Œç—‡æ•°æ®é›†")
            return

        if max_datasets:
            cancer_datasets = cancer_datasets[:max_datasets]
            print(f"ğŸ¯ é™åˆ¶åˆ†æå‰ {max_datasets} ä¸ªæ•°æ®é›†")

        print(f"ğŸ“‹ æ€»å…±éœ€è¦åˆ†æ {len(cancer_datasets)} ä¸ªæ•°æ®é›†")

        # æ˜¾ç¤ºæ–­ç‚¹ç»­ä¼ çŠ¶æ€
        if self.enable_resume:
            remaining_datasets = [ds for ds in cancer_datasets if not self.is_dataset_completed(ds)]
            completed_count = len(cancer_datasets) - len(remaining_datasets)
            print(f"ğŸ”„ æ–­ç‚¹ç»­ä¼ : å·²å®Œæˆ {completed_count} ä¸ªï¼Œå‰©ä½™ {len(remaining_datasets)} ä¸ªæ•°æ®é›†")
            cancer_datasets = remaining_datasets

        if len(cancer_datasets) == 0:
            print("âœ… æ‰€æœ‰æ•°æ®é›†éƒ½å·²å®Œæˆåˆ†æï¼ŒåŠ è½½ç¼“å­˜ç»“æœ...")
            # åŠ è½½æ‰€æœ‰ç¼“å­˜ç»“æœ
            all_group_stats = []
            all_stat_tests = []
            successful_datasets = []

            for dataset_id in self.completed_datasets:
                cached_group_stats, cached_stat_tests = self.load_cached_results(dataset_id)
                if cached_group_stats is not None:
                    all_group_stats.append(cached_group_stats)
                    successful_datasets.append(dataset_id)
                    if cached_stat_tests is not None:
                        all_stat_tests.append(cached_stat_tests)
        else:
            # å­˜å‚¨æ‰€æœ‰ç»“æœ
            all_group_stats = []
            all_stat_tests = []
            successful_datasets = []

            # å…ˆåŠ è½½å·²å®Œæˆçš„ç¼“å­˜ç»“æœ
            for dataset_id in self.completed_datasets:
                cached_group_stats, cached_stat_tests = self.load_cached_results(dataset_id)
                if cached_group_stats is not None:
                    all_group_stats.append(cached_group_stats)
                    successful_datasets.append(dataset_id)
                    if cached_stat_tests is not None:
                        all_stat_tests.append(cached_stat_tests)

            # åˆ†æå‰©ä½™æ•°æ®é›†
            if TQDM_AVAILABLE:
                dataset_iterator = tqdm(cancer_datasets, desc="åˆ†ææ•°æ®é›†", unit="æ•°æ®é›†")
            else:
                dataset_iterator = cancer_datasets

            for dataset_id in dataset_iterator:
                if not TQDM_AVAILABLE:
                    print(f"\nğŸ“Š å¤„ç†æ•°æ®é›†: {dataset_id}")

                grouped_data, group_stats, stat_tests = self.analyze_single_dataset(dataset_id)

                if group_stats is not None and len(group_stats) > 0:
                    all_group_stats.append(group_stats)
                    successful_datasets.append(dataset_id)

                    if stat_tests is not None and len(stat_tests) > 0:
                        all_stat_tests.append(stat_tests)

        if len(all_group_stats) == 0:
            print("âŒ æ²¡æœ‰æˆåŠŸåˆ†æçš„æ•°æ®é›†")
            return

        # åˆå¹¶æ‰€æœ‰ç»“æœ
        print(f"\nğŸ“ˆ åˆå¹¶åˆ†æç»“æœ...")
        final_group_stats = pd.concat(all_group_stats, ignore_index=True)

        if len(all_stat_tests) > 0:
            final_stat_tests = pd.concat(all_stat_tests, ignore_index=True)
        else:
            final_stat_tests = pd.DataFrame()

        # ä¿å­˜ç»“æœ
        print(f"ğŸ’¾ ä¿å­˜ç»“æœ...")

        group_stats_file = os.path.join(self.output_dir, 'group_stats.csv')
        final_group_stats.to_csv(group_stats_file, index=False, encoding='utf-8')
        print(f"  âœ… ä¿å­˜: group_stats.csv")

        if len(final_stat_tests) > 0:
            stat_tests_file = os.path.join(self.output_dir, 'stat_tests.csv')
            final_stat_tests.to_csv(stat_tests_file, index=False, encoding='utf-8')
            print(f"  âœ… ä¿å­˜: stat_tests.csv")

        # åˆ›å»ºå…¨å±€çƒ­å›¾
        self.create_global_heatmap(final_group_stats)

        # åˆ›å»ºæ•°æ®é›†çº§åˆ«è¶‹åŠ¿å›¾
        self.create_dataset_trend_plots(final_group_stats)

        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        self.generate_analysis_report(final_group_stats, final_stat_tests, successful_datasets)

        print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
        print(f"âœ… æˆåŠŸåˆ†æäº† {len(successful_datasets)} ä¸ªæ•°æ®é›†")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {self.output_dir}/")
        print(f"ğŸ“Š å›¾è¡¨ä¿å­˜åœ¨: {self.fig_dir}/")

        return final_group_stats, final_stat_tests

    def create_global_heatmap(self, group_stats_df: pd.DataFrame):
        """åˆ›å»ºå…¨å±€çƒ­å›¾"""

        print("ğŸ”¥ åˆ›å»ºå…¨å±€çƒ­å›¾...")

        try:
            # è®¡ç®—ç›¸å¯¹äºWT-onlyçš„å·®å¼‚
            heatmap_data = []

            for dataset_id in group_stats_df['dataset_id'].unique():
                dataset_data = group_stats_df[group_stats_df['dataset_id'] == dataset_id]

                for prop in self.property_names:
                    prop_data = dataset_data[dataset_data['property'] == prop]

                    # è·å–WT-onlyä½œä¸ºåŸºå‡†
                    wt_only = prop_data[prop_data['peptide_group'] == 'WT-only']
                    if len(wt_only) == 0:
                        continue

                    wt_median = wt_only['median'].iloc[0]

                    # è®¡ç®—å…¶ä»–ç»„ç›¸å¯¹äºWT-onlyçš„å·®å¼‚
                    for group in ['PTM-only', 'PTM + WT']:
                        group_data = prop_data[prop_data['peptide_group'] == group]
                        if len(group_data) > 0:
                            group_median = group_data['median'].iloc[0]
                            delta = group_median - wt_median

                            heatmap_data.append({
                                'dataset_id': dataset_id,
                                'property': prop,
                                'group': group,
                                'delta': delta
                            })

            if len(heatmap_data) == 0:
                print("âš ï¸  æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®åˆ›å»ºçƒ­å›¾")
                return

            heatmap_df = pd.DataFrame(heatmap_data)

            # ä¸ºæ¯ä¸ªç†åŒ–æ€§è´¨åˆ›å»ºçƒ­å›¾
            for prop in self.property_names:
                prop_data = heatmap_df[heatmap_df['property'] == prop]

                if len(prop_data) == 0:
                    continue

                # åˆ›å»ºæ•°æ®é€è§†è¡¨
                pivot_data = prop_data.pivot(index='dataset_id', columns='group', values='delta')

                if pivot_data.empty:
                    continue

                # åˆ›å»ºçƒ­å›¾
                fig, ax = plt.subplots(1, 1, figsize=(8, max(12, len(pivot_data) * 0.3)))

                # é€‰æ‹©åˆé€‚çš„é¢œè‰²æ˜ å°„
                if prop in ['pI', 'Net_Charge']:
                    cmap = 'RdBu_r'
                    center = 0
                elif prop == 'Hydrophobicity_KD':
                    cmap = 'RdYlBu_r'
                    center = 0
                else:  # Molecular_Weight
                    cmap = 'viridis'
                    center = None

                sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap=cmap, center=center,
                           ax=ax, cbar_kws={'label': f'Î”{prop} (vs WT-only)'})

                ax.set_title(f'Global Heatmap: Î”{prop} Across Datasets',
                           fontsize=14, fontweight='bold')
                ax.set_xlabel('Peptide Group', fontsize=12)
                ax.set_ylabel('Dataset ID', fontsize=12)

                plt.tight_layout()

                # ä¿å­˜å›¾ç‰‡
                filename = f'global_heatmap_{prop}.png'
                filepath = os.path.join(self.fig_dir, filename)
                plt.savefig(filepath, dpi=300, bbox_inches='tight')
                plt.close()

                print(f"  âœ… ä¿å­˜: {filename}")

            # åˆ›å»ºç»¼åˆçƒ­å›¾ï¼ˆæ‰€æœ‰æ€§è´¨åœ¨ä¸€å¼ å›¾ä¸Šï¼‰
            self.create_comprehensive_heatmap(heatmap_df)

        except Exception as e:
            print(f"âŒ åˆ›å»ºçƒ­å›¾å¤±è´¥: {e}")

    def create_comprehensive_heatmap(self, heatmap_df: pd.DataFrame):
        """åˆ›å»ºç»¼åˆçƒ­å›¾ï¼ˆ4ä¸ªæ€§è´¨ Ã— 2ä¸ªç»„ï¼‰"""

        try:
            # é‡æ–°ç»„ç»‡æ•°æ®ï¼šdataset Ã— (property_group)
            comprehensive_data = []

            for dataset_id in heatmap_df['dataset_id'].unique():
                dataset_data = heatmap_df[heatmap_df['dataset_id'] == dataset_id]
                row_data = {'dataset_id': dataset_id}

                for prop in self.property_names:
                    prop_data = dataset_data[dataset_data['property'] == prop]

                    for group in ['PTM-only', 'PTM + WT']:
                        group_data = prop_data[prop_data['group'] == group]
                        col_name = f'{prop}_{group}'

                        if len(group_data) > 0:
                            row_data[col_name] = group_data['delta'].iloc[0]
                        else:
                            row_data[col_name] = np.nan

                comprehensive_data.append(row_data)

            comp_df = pd.DataFrame(comprehensive_data)
            comp_df = comp_df.set_index('dataset_id')

            # ç§»é™¤å…¨ä¸ºNaNçš„åˆ—
            comp_df = comp_df.dropna(axis=1, how='all')

            if comp_df.empty:
                print("âš ï¸  æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®åˆ›å»ºç»¼åˆçƒ­å›¾")
                return

            # åˆ›å»ºç»¼åˆçƒ­å›¾
            fig, ax = plt.subplots(1, 1, figsize=(12, max(10, len(comp_df) * 0.25)))

            sns.heatmap(comp_df, annot=True, fmt='.2f', cmap='RdBu_r', center=0,
                       ax=ax, cbar_kws={'label': 'Î” Value (vs WT-only)'})

            ax.set_title('Comprehensive Heatmap: All Properties Across Datasets',
                        fontsize=16, fontweight='bold')
            ax.set_xlabel('Property Ã— Group', fontsize=12)
            ax.set_ylabel('Dataset ID', fontsize=12)

            # æ—‹è½¬xè½´æ ‡ç­¾
            plt.xticks(rotation=45, ha='right')
            plt.tight_layout()

            # ä¿å­˜å›¾ç‰‡
            filename = 'global_heatmap_comprehensive.png'
            filepath = os.path.join(self.fig_dir, filename)
            plt.savefig(filepath, dpi=300, bbox_inches='tight')
            plt.close()

            print(f"  âœ… ä¿å­˜: {filename}")

        except Exception as e:
            print(f"âŒ åˆ›å»ºç»¼åˆçƒ­å›¾å¤±è´¥: {e}")

    def create_dataset_trend_plots(self, group_stats_df: pd.DataFrame):
        """åˆ›å»ºæ•°æ®é›†çº§åˆ«çš„è¶‹åŠ¿å›¾"""

        print("ğŸ“ˆ åˆ›å»ºæ•°æ®é›†çº§åˆ«è¶‹åŠ¿å›¾...")

        try:
            # è·å–æ‰€æœ‰ä¿®é¥°ç±»å‹å’Œæ•°æ®é›†
            modifications = group_stats_df['modification_type'].unique()
            datasets = sorted(group_stats_df['dataset_id'].unique())

            if len(datasets) < 2:
                print("âš ï¸  æ•°æ®é›†æ•°é‡ä¸è¶³ï¼Œæ— æ³•åˆ›å»ºè¶‹åŠ¿å›¾")
                return

            # ä¸ºæ¯ç§ä¿®é¥°ç±»å‹åˆ›å»ºè¶‹åŠ¿å›¾
            for modification_type in modifications:
                print(f"  ğŸ“Š ç»˜åˆ¶ {modification_type} çš„è¶‹åŠ¿å›¾...")

                mod_data = group_stats_df[group_stats_df['modification_type'] == modification_type]

                if len(mod_data) == 0:
                    continue

                # åˆ›å»º2x2å­å›¾å¸ƒå±€
                fig, axes = plt.subplots(2, 2, figsize=(16, 12))
                fig.suptitle(f'{modification_type} - Dataset-level Trends Across Properties',
                           fontsize=16, fontweight='bold')

                axes = axes.flatten()

                # ä¸ºæ¯ä¸ªç†åŒ–æ€§è´¨åˆ›å»ºè¶‹åŠ¿å›¾
                for i, prop_name in enumerate(self.property_names):
                    ax = axes[i]

                    prop_data = mod_data[mod_data['property'] == prop_name]

                    if len(prop_data) == 0:
                        ax.text(0.5, 0.5, f'No data for {prop_name}',
                               ha='center', va='center', transform=ax.transAxes)
                        ax.set_title(f'{prop_name}')
                        continue

                    # å‡†å¤‡è¶‹åŠ¿æ•°æ®
                    trend_data = {}
                    for group in ['PTM-only', 'PTM + WT', 'WT-only']:
                        group_prop_data = prop_data[prop_data['peptide_group'] == group]

                        if len(group_prop_data) > 0:
                            # æŒ‰æ•°æ®é›†æ’åº
                            group_prop_data = group_prop_data.sort_values('dataset_id')
                            trend_data[group] = {
                                'datasets': group_prop_data['dataset_id'].tolist(),
                                'medians': group_prop_data['median'].tolist(),
                                'counts': group_prop_data['count'].tolist()
                            }

                    # ç»˜åˆ¶è¶‹åŠ¿çº¿
                    colors = {'PTM-only': '#e74c3c', 'PTM + WT': '#f39c12', 'WT-only': '#3498db'}
                    markers = {'PTM-only': 'o', 'PTM + WT': 's', 'WT-only': '^'}

                    for group, data in trend_data.items():
                        if len(data['datasets']) > 0:
                            # åˆ›å»ºxè½´ä½ç½®ï¼ˆæ•°æ®é›†ç´¢å¼•ï¼‰
                            x_positions = [datasets.index(ds) for ds in data['datasets']]

                            # ç»˜åˆ¶è¶‹åŠ¿çº¿
                            ax.plot(x_positions, data['medians'],
                                   color=colors[group], marker=markers[group],
                                   linewidth=2, markersize=8, label=group, alpha=0.8)

                            # æ·»åŠ æ•°æ®ç‚¹çš„è®¡æ•°ä¿¡æ¯ï¼ˆä½œä¸ºç‚¹çš„å¤§å°ï¼‰
                            sizes = [min(max(count/100, 10), 200) for count in data['counts']]
                            ax.scatter(x_positions, data['medians'],
                                     s=sizes, color=colors[group], alpha=0.3, edgecolors='white')

                    # è®¾ç½®å›¾è¡¨å±æ€§
                    ax.set_title(f'{prop_name}', fontsize=12, fontweight='bold')
                    ax.set_xlabel('Dataset', fontsize=10)
                    ax.set_ylabel(f'{prop_name}', fontsize=10)
                    ax.legend(fontsize=9)
                    ax.grid(True, alpha=0.3)

                    # è®¾ç½®xè½´æ ‡ç­¾
                    ax.set_xticks(range(len(datasets)))
                    ax.set_xticklabels([ds.replace('PXD', '') for ds in datasets],
                                      rotation=45, ha='right', fontsize=8)

                    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                    info_text = f"Datasets: {len(set().union(*[data['datasets'] for data in trend_data.values()]))}"
                    ax.text(0.02, 0.98, info_text, transform=ax.transAxes,
                           verticalalignment='top', fontsize=8,
                           bbox=dict(boxstyle='round,pad=0.3', facecolor='wheat', alpha=0.7))

                plt.tight_layout()

                # ä¿å­˜å›¾ç‰‡
                clean_mod_name = modification_type.replace('[', '_').replace(']', '_').replace('/', '_')
                filename = f'dataset_trends_{clean_mod_name}.png'
                filepath = os.path.join(self.fig_dir, filename)
                plt.savefig(filepath, dpi=300, bbox_inches='tight')
                plt.close()

                print(f"    âœ… ä¿å­˜: {filename}")

            # åˆ›å»ºç»¼åˆè¶‹åŠ¿å›¾ï¼ˆæ‰€æœ‰ä¿®é¥°ç±»å‹åœ¨ä¸€å¼ å›¾ä¸Šï¼‰
            self.create_comprehensive_trend_plot(group_stats_df, datasets)

        except Exception as e:
            print(f"âŒ åˆ›å»ºè¶‹åŠ¿å›¾å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    def create_comprehensive_trend_plot(self, group_stats_df: pd.DataFrame, datasets: list):
        """åˆ›å»ºç»¼åˆè¶‹åŠ¿å›¾ï¼ˆæ‰€æœ‰ä¿®é¥°ç±»å‹ï¼‰"""

        try:
            print("  ğŸ“Š ç»˜åˆ¶ç»¼åˆè¶‹åŠ¿å›¾...")

            # ä¸ºæ¯ä¸ªç†åŒ–æ€§è´¨åˆ›å»ºä¸€ä¸ªç»¼åˆå›¾
            for prop_name in self.property_names:
                fig, axes = plt.subplots(1, 3, figsize=(18, 6))
                fig.suptitle(f'All Modifications - {prop_name} Trends Across Datasets',
                           fontsize=16, fontweight='bold')

                groups = ['PTM-only', 'PTM + WT', 'WT-only']
                colors = plt.cm.Set3(np.linspace(0, 1, len(group_stats_df['modification_type'].unique())))

                for group_idx, group in enumerate(groups):
                    ax = axes[group_idx]
                    ax.set_title(f'{group}', fontsize=14, fontweight='bold')

                    # ä¸ºæ¯ç§ä¿®é¥°ç±»å‹ç»˜åˆ¶è¶‹åŠ¿çº¿
                    for mod_idx, modification_type in enumerate(group_stats_df['modification_type'].unique()):
                        mod_group_data = group_stats_df[
                            (group_stats_df['modification_type'] == modification_type) &
                            (group_stats_df['peptide_group'] == group) &
                            (group_stats_df['property'] == prop_name)
                        ]

                        if len(mod_group_data) > 1:  # è‡³å°‘éœ€è¦2ä¸ªæ•°æ®ç‚¹
                            # æŒ‰æ•°æ®é›†æ’åº
                            mod_group_data = mod_group_data.sort_values('dataset_id')

                            # åˆ›å»ºxè½´ä½ç½®
                            x_positions = [datasets.index(ds) for ds in mod_group_data['dataset_id']]
                            y_values = mod_group_data['median'].tolist()

                            # ç»˜åˆ¶è¶‹åŠ¿çº¿
                            ax.plot(x_positions, y_values,
                                   color=colors[mod_idx], marker='o',
                                   linewidth=2, markersize=6,
                                   label=modification_type, alpha=0.8)

                    # è®¾ç½®å›¾è¡¨å±æ€§
                    ax.set_xlabel('Dataset', fontsize=12)
                    ax.set_ylabel(f'{prop_name}', fontsize=12)
                    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
                    ax.grid(True, alpha=0.3)

                    # è®¾ç½®xè½´æ ‡ç­¾
                    ax.set_xticks(range(len(datasets)))
                    ax.set_xticklabels([ds.replace('PXD', '') for ds in datasets],
                                      rotation=45, ha='right', fontsize=10)

                plt.tight_layout()

                # ä¿å­˜å›¾ç‰‡
                filename = f'comprehensive_trends_{prop_name}.png'
                filepath = os.path.join(self.fig_dir, filename)
                plt.savefig(filepath, dpi=300, bbox_inches='tight')
                plt.close()

                print(f"    âœ… ä¿å­˜: {filename}")

        except Exception as e:
            print(f"âŒ åˆ›å»ºç»¼åˆè¶‹åŠ¿å›¾å¤±è´¥: {e}")

    def generate_analysis_report(self, group_stats_df: pd.DataFrame,
                               stat_tests_df: pd.DataFrame, successful_datasets: list):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""

        report_file = os.path.join(self.output_dir, 'analysis_report.txt')

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("è‚½æ®µåˆ†ç»„åˆ†ææŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")

            # æ€»ä½“ç»Ÿè®¡
            f.write("æ€»ä½“ç»Ÿè®¡:\n")
            f.write(f"  æˆåŠŸåˆ†ææ•°æ®é›†æ•°é‡: {len(successful_datasets)}\n")
            f.write(f"  æ€»åˆ†æè®°å½•æ•°: {len(group_stats_df)}\n")
            f.write(f"  ç»Ÿè®¡æ£€éªŒè®°å½•æ•°: {len(stat_tests_df)}\n\n")

            # æ•°æ®é›†åˆ—è¡¨
            f.write("æˆåŠŸåˆ†æçš„æ•°æ®é›†:\n")
            for i, dataset in enumerate(successful_datasets, 1):
                f.write(f"  {i:2d}. {dataset}\n")
            f.write("\n")

            # åˆ†ç»„ç»Ÿè®¡
            f.write("è‚½æ®µåˆ†ç»„ç»Ÿè®¡:\n")
            group_summary = group_stats_df.groupby('peptide_group')['count'].agg(['sum', 'mean', 'std']).round(2)
            for group, stats in group_summary.iterrows():
                f.write(f"  {group}:\n")
                f.write(f"    æ€»è‚½æ®µæ•°: {stats['sum']:,.0f}\n")
                f.write(f"    å¹³å‡æ¯æ•°æ®é›†: {stats['mean']:.0f} Â± {stats['std']:.0f}\n")
            f.write("\n")

            # ç†åŒ–æ€§è´¨ç»Ÿè®¡
            f.write("ç†åŒ–æ€§è´¨ç»Ÿè®¡ (å„ç»„ä¸­ä½æ•°):\n")
            for prop in self.property_names:
                f.write(f"\n  {prop}:\n")
                prop_data = group_stats_df[group_stats_df['property'] == prop]
                prop_summary = prop_data.groupby('peptide_group')['median'].agg(['mean', 'std']).round(3)

                for group, stats in prop_summary.iterrows():
                    f.write(f"    {group}: {stats['mean']:.3f} Â± {stats['std']:.3f}\n")

            # æ˜¾è‘—æ€§æ£€éªŒæ±‡æ€»
            if len(stat_tests_df) > 0:
                f.write("\n\næ˜¾è‘—æ€§æ£€éªŒæ±‡æ€»:\n")

                # Kruskal-Wallisæ£€éªŒç»“æœ
                kw_tests = stat_tests_df[stat_tests_df['test_type'] == 'Kruskal-Wallis']
                if len(kw_tests) > 0:
                    f.write("  Kruskal-Wallisæ£€éªŒ (æ€»ä½“å·®å¼‚):\n")
                    for prop in self.property_names:
                        prop_tests = kw_tests[kw_tests['property'] == prop]
                        if len(prop_tests) > 0:
                            sig_count = prop_tests['significant'].sum()
                            total_count = len(prop_tests)
                            f.write(f"    {prop}: {sig_count}/{total_count} æ•°æ®é›†æ˜¾è‘— "
                                   f"({sig_count/total_count*100:.1f}%)\n")

                # ä¸¤ä¸¤æ¯”è¾ƒç»“æœ
                pairwise_tests = stat_tests_df[stat_tests_df['test_type'] == 'Mann-Whitney U']
                if len(pairwise_tests) > 0:
                    f.write("\n  ä¸¤ä¸¤æ¯”è¾ƒ (Mann-Whitney U):\n")
                    comparison_summary = pairwise_tests.groupby('comparison')['significant'].agg(['sum', 'count'])
                    for comparison, stats in comparison_summary.iterrows():
                        sig_rate = stats['sum'] / stats['count'] * 100
                        f.write(f"    {comparison}: {stats['sum']}/{stats['count']} æ˜¾è‘— "
                               f"({sig_rate:.1f}%)\n")

        print(f"  âœ… ä¿å­˜: analysis_report.txt")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§¬ è‚½æ®µåˆ†ç»„åˆ†æå·¥å…·")
    print("=" * 60)
    print("æ ¹æ®ä¿®é¥°æ£€æµ‹æƒ…å†µå°†è‚½æ®µåˆ†ä¸ºä¸‰ç»„è¿›è¡Œæ¯”è¾ƒåˆ†æ")
    print("- PTM-only: åªæ£€æµ‹åˆ°ä¿®é¥°å½¢æ€")
    print("- PTM + WT: åŒåºåˆ—åŒæ—¶æ£€æµ‹åˆ°ä¿®é¥°ä¸æœªä¿®é¥°è‚½")
    print("- WT-only: åªæ£€æµ‹åˆ°æœªä¿®é¥°è‚½")
    print("=" * 60)

    # åˆ›å»ºåˆ†æå™¨
    analyzer = PeptideGroupAnalyzer()

    # è¿è¡Œåˆ†æï¼ˆå¯ä»¥è®¾ç½®é™åˆ¶ç”¨äºæµ‹è¯•ï¼‰
    # results = analyzer.run_full_analysis(max_datasets=3)  # æµ‹è¯•ç”¨
    results = analyzer.run_full_analysis()  # å®Œæ•´åˆ†æ

    if results is not None:
        group_stats, stat_tests = results
        print(f"\nğŸ“Š åˆ†æç»“æœæ±‡æ€»:")
        print(f"- åˆ†ç»„ç»Ÿè®¡è®°å½•: {len(group_stats)}")
        print(f"- ç»Ÿè®¡æ£€éªŒè®°å½•: {len(stat_tests)}")
        print(f"- è¾“å‡ºç›®å½•: {analyzer.output_dir}")
        print(f"- å›¾è¡¨ç›®å½•: {analyzer.fig_dir}")
    else:
        print("âŒ åˆ†æå¤±è´¥")


if __name__ == "__main__":
    main()
